{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZJeLZaQub5Q"
      },
      "outputs": [],
      "source": [
        "!pip install -q gdown\n",
        "import gdown\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = '1hdItv8l8Qj102oAB75la9XubqYydxbkD'\n",
        "output = 'dataset.csv'  # You can rename this if you want\n",
        "\n",
        "gdown.download(f'https://drive.google.com/uc?id={file_id}', output, quiet=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "F7Zwnd3oueCp",
        "outputId": "4c0449b5-e9cf-457c-cc94-06a6e919901e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1hdItv8l8Qj102oAB75la9XubqYydxbkD\n",
            "From (redirected): https://drive.google.com/uc?id=1hdItv8l8Qj102oAB75la9XubqYydxbkD&confirm=t&uuid=4102cf6d-acce-4544-afb0-731c664979c7\n",
            "To: /content/dataset.csv\n",
            "100%|██████████| 4.19G/4.19G [00:38<00:00, 110MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dataset.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the entire dataset\n",
        "df = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Total number of rows\n",
        "total_rows = len(df)\n",
        "\n",
        "# Number of rows per split (10%)\n",
        "rows_per_split = total_rows // 10\n",
        "\n",
        "# Split and save\n",
        "for i in range(10):\n",
        "    start_row = i * rows_per_split\n",
        "    end_row = (i + 1) * rows_per_split if i < 9 else total_rows  # last chunk takes all remaining rows\n",
        "\n",
        "    df_part = df.iloc[start_row:end_row]\n",
        "    df_part.to_csv(f'dataset_part_{i+1}.csv', index=False)\n",
        "\n",
        "print(\"✅ Dataset split into 10 parts successfully.\")"
      ],
      "metadata": {
        "id": "TQJTDguqumbW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}